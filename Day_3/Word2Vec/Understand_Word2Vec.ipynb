{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "div.cell { /* Tunes the space between cells */\n",
       "margin-top:1em;\n",
       "margin-bottom:1em;\n",
       "}\n",
       "\n",
       "div.text_cell_render h1 { /* Main titles bigger, centered */\n",
       "font-size: 2.0em;\n",
       "line-height:1.6em;\n",
       "text-align:center;\n",
       "}\n",
       "\n",
       "div.text_cell_render h2 { /*  Parts names nearer from text */\n",
       "margin-bottom: 1em;\n",
       "text-align:center;\n",
       "}\n",
       "\n",
       "\n",
       "div.text_cell_render { /* Customize text cells */\n",
       "font-family: 'Times New Roman';\n",
       "font-size:1.2em;\n",
       "line-height:1.2em;\n",
       "padding-left:1em;\n",
       "padding-right:3em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "\n",
    "div.cell { /* Tunes the space between cells */\n",
    "margin-top:1em;\n",
    "margin-bottom:1em;\n",
    "}\n",
    "\n",
    "div.text_cell_render h1 { /* Main titles bigger, centered */\n",
    "font-size: 2.0em;\n",
    "line-height:1.6em;\n",
    "text-align:center;\n",
    "}\n",
    "\n",
    "div.text_cell_render h2 { /*  Parts names nearer from text */\n",
    "margin-bottom: 1em;\n",
    "text-align:center;\n",
    "}\n",
    "\n",
    "\n",
    "div.text_cell_render { /* Customize text cells */\n",
    "font-family: 'Times New Roman';\n",
    "font-size:1.2em;\n",
    "line-height:1.2em;\n",
    "padding-left:1em;\n",
    "padding-right:3em;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It's all about Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jalajthanaki/Pune_meetup/master/Day_3/Word2Vec/images/Image_1_1.gif\" \n",
    "align=\"middle\" alt=\"Image_1_1\" data-canonical-src=\"\" style=\"width:90%;height:90%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "1. Why do we need Word2Vec?\n",
    "\n",
    "2. What is Word2Vec?\n",
    "\n",
    "3. Architecture of Word2Vec\n",
    "\n",
    "4. Components of Word2Vec\n",
    "    \n",
    "    4.1 Vocabulary Builder\n",
    "    \n",
    "    4.2 Context Builder\n",
    "    \n",
    "    4.3 One-hot encoding\n",
    "    \n",
    "    4.4 Skip-Gram\n",
    "    \n",
    "    4.5 Continuous Bag of Words\n",
    "\n",
    "5. Math behind Word2Vec\n",
    "\n",
    "    5.1 Structure Highlights\n",
    "    \n",
    "    5.2 Small math example\n",
    "    \n",
    "    5.3 Softmax function\n",
    "\n",
    "    5.4 Error Function\n",
    "\n",
    "6. Understanding of T-SNE \n",
    "    \n",
    "7. Let's start hands on session\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we need Word2Vec?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Semantics is important...!\n",
    "\n",
    "\n",
    "* Lexical Semantics and Distributional Semantics\n",
    "\n",
    "\n",
    "* We are focusing of Distributional Semantics\n",
    "\n",
    "\n",
    "* Computer cannot do computations on strings\n",
    "\n",
    "\n",
    "* Strings don’t hold much explicit information themselves.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Facts:__\n",
    "\n",
    "\n",
    "* Is Word2Vec having Deep Neural Networks? The answer is: __NO__ \n",
    "\n",
    "\n",
    "* It's has only 3 layers...!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Word2Vec?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Word2Vec is the representation of words in numerical format. \n",
    "\n",
    "\n",
    "* Words Vectors are usually dense vector representations\n",
    "\n",
    "\n",
    "* It generates high-dimensional vector space for words. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture of Word2Vec\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jalajthanaki/Pune_meetup/master/Day_3/Word2Vec/images/Image_1_2.png\" \n",
    "align=\"middle\" alt=\"Image_1_2\" data-canonical-src=\"\" style=\"width:80%;height:80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;\">Image credit goes to [Xin Rong](https://docs.google.com/presentation/d/1yQWN1CDWLzxGeIAvnGgDsIJr5xmy4dB0VmHFKkLiibo/pub?start=false&loop=false&delayms=3000&slide=id.p)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jalajthanaki/Pune_meetup/master/Day_3/Word2Vec/images/Image_1_3.png\" \n",
    "align=\"middle\" alt=\"Image_1_3\" data-canonical-src=\"\" style=\"width:100%;height:100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;\">Image credit goes to [Xin Rong](https://docs.google.com/presentation/d/1yQWN1CDWLzxGeIAvnGgDsIJr5xmy4dB0VmHFKkLiibo/pub?start=false&loop=false&delayms=3000&slide=id.p)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Logic behind Word2Vec\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jalajthanaki/Pune_meetup/master/Day_3/Word2Vec/images/Image_1_4.png\" \n",
    "align=\"middle\" alt=\"Image_1_4\" data-canonical-src=\"\" style=\"width:100%;height:100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;\">Image credit goes to [Xin Rong](https://docs.google.com/presentation/d/1yQWN1CDWLzxGeIAvnGgDsIJr5xmy4dB0VmHFKkLiibo/pub?start=false&loop=false&delayms=3000&slide=id.p)</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components of Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It takes input in form of raw sentences and generate vocabulary in form of unique words from sentence.\n",
    "\n",
    "```\n",
    "Example: he is a boy\n",
    "\n",
    "```\n",
    "* Then Vocabulary Builder builds the vocabulary of four words\n",
    "\n",
    "* In gensim, Vocabulary builder object has word index and its count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "Word2Vec(vocab=14, size=100, alpha=0.025)\n",
      "['is', 'sentence', 'for', 'the', 'yet', 'final', 'another', 'and', 'one', 'second', 'this', 'word2vec', 'more', 'first']\n",
      "[ 9.6209993e-04  1.1460621e-04 -1.7711769e-03  3.3680422e-03\n",
      "  4.8903595e-03  4.6888622e-03  3.3843378e-03  3.4872207e-03\n",
      " -4.7312952e-03  1.8418371e-03  3.5851102e-03  1.2439444e-05\n",
      "  2.3683887e-03  3.5339796e-03  2.8494007e-03 -4.9129911e-03\n",
      "  3.4092639e-03  1.2433403e-03 -1.1899451e-03 -4.2076892e-04\n",
      "  4.0362068e-04 -9.1121887e-04 -3.1746463e-03 -6.7561254e-04\n",
      " -3.1773427e-03 -2.8699592e-03  1.1373522e-03  3.4800526e-03\n",
      " -3.5573866e-03 -4.0761065e-03  2.2884090e-03 -4.9946909e-03\n",
      " -2.4393133e-03  4.8761251e-03  2.9834078e-03  3.5438270e-03\n",
      " -2.7117445e-03 -2.2728250e-03 -7.6571357e-04 -1.6194864e-04\n",
      "  4.8126457e-03  4.8328258e-04 -2.7524051e-04  4.8499787e-03\n",
      " -4.2203250e-03  3.9255717e-03  4.7141765e-03  1.7306578e-03\n",
      " -2.6565874e-03  8.0700504e-04  1.6679820e-03 -1.7008991e-03\n",
      " -1.1773859e-03  2.6441435e-03  1.4003506e-03  4.4028722e-03\n",
      " -4.4409791e-03  2.3740171e-03 -1.1208911e-03 -1.0785805e-03\n",
      " -3.4532824e-03  1.0825823e-03 -1.1653589e-03  3.4915754e-03\n",
      "  2.9408247e-03  3.7986082e-03  6.8310043e-04 -1.2086667e-03\n",
      "  3.9777886e-03 -1.6696076e-03  6.9061352e-04  4.1561378e-03\n",
      "  1.5729673e-03  3.1377189e-03 -3.6514219e-04 -3.7421400e-03\n",
      "  2.5097956e-03  1.0551373e-03  3.9778203e-03  2.2746139e-04\n",
      "  5.8719696e-04  7.9736713e-04 -4.7517172e-03 -3.6769055e-03\n",
      " -3.9773071e-03 -1.0180451e-03 -3.5270320e-03 -4.8330058e-03\n",
      " -3.6074973e-03  3.9071250e-03 -2.6467473e-03 -4.9726618e-04\n",
      "  2.0661829e-03  1.9062120e-03  1.2441858e-03 -8.3953993e-05\n",
      "  3.4446416e-03 -3.9369445e-03 -2.5692093e-03 -6.0016458e-04]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8fd0fae3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot\n",
    "%pylab inline\n",
    "# define training data\n",
    "sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n",
    "\t\t\t['this', 'is', 'the', 'second', 'sentence'],\n",
    "\t\t\t['yet', 'another', 'sentence'],\n",
    "\t\t\t['one', 'more', 'sentence'],\n",
    "\t\t\t['and', 'the', 'final', 'sentence']]\n",
    "# train model\n",
    "model = Word2Vec(sentences, min_count=1,size=100)\n",
    "#model = gensim.models.Word2Vec(sentences, size=150, window=10, min_count=2, workers=10)\n",
    "\n",
    "# summarize the loaded model\n",
    "print(model)\n",
    "# summarize vocabulary\n",
    "words = list(model.wv.vocab)\n",
    "print(words)\n",
    "# access vector for one word\n",
    "print(model['sentence'])\n",
    "\n",
    "\n",
    "\n",
    "# fit a 2d PCA model to the vectors\n",
    "X = model[model.wv.vocab]\n",
    "pca = PCA(n_components=2)\n",
    "result = pca.fit_transform(X)\n",
    "# create a scatter plot of the projection\n",
    "pyplot.scatter(result[:, 0], result[:, 1])\n",
    "words = list(model.wv.vocab)\n",
    "for i, word in enumerate(words):\n",
    "\tpyplot.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Builder\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Context Builder__ is kind of sliding window. It is specified by number and direction\n",
    "\n",
    "\n",
    "* It's kind of n-gram algorithms.\n",
    "\n",
    "\n",
    "* It uses output of Vocabulary builder as input.\n",
    "\n",
    "\n",
    "* Context builder generate word pairs. \n",
    "\n",
    "\n",
    "* Note that: If the word is at the beginning or ending of sentence, the window ignores the outer words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jalajthanaki/Pune_meetup/master/Day_3/Word2Vec/images/Image_1_5.png\" \n",
    "align=\"middle\" alt=\"Image_1_5\" data-canonical-src=\"\" style=\"width:100%;height:100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Sentences----------\n",
      "[['he', 'is', 'the', 'king'], ['the', 'king', 'is', 'royal'], ['she', 'is', 'the', 'royal', 'queen']]\n",
      "\n",
      "\n",
      "-----------Word Pairs-------\n",
      "Word:  he\n",
      "['he ------- is']\n",
      "['he ------- the']\n",
      "Word:  is\n",
      "['is ------- he']\n",
      "['is ------- the']\n",
      "['is ------- king']\n",
      "Word:  the\n",
      "['the ------- he']\n",
      "['the ------- is']\n",
      "['the ------- king']\n",
      "Word:  king\n",
      "['king ------- is']\n",
      "['king ------- the']\n",
      "\n",
      "\n",
      "-----------Word Pairs-------\n",
      "Word:  the\n",
      "['the ------- king']\n",
      "['the ------- is']\n",
      "Word:  king\n",
      "['king ------- the']\n",
      "['king ------- is']\n",
      "['king ------- royal']\n",
      "Word:  is\n",
      "['is ------- the']\n",
      "['is ------- king']\n",
      "['is ------- royal']\n",
      "Word:  royal\n",
      "['royal ------- king']\n",
      "['royal ------- is']\n",
      "\n",
      "\n",
      "-----------Word Pairs-------\n",
      "Word:  she\n",
      "['she ------- is']\n",
      "['she ------- the']\n",
      "Word:  is\n",
      "['is ------- she']\n",
      "['is ------- the']\n",
      "['is ------- royal']\n",
      "Word:  the\n",
      "['the ------- she']\n",
      "['the ------- is']\n",
      "['the ------- royal']\n",
      "['the ------- queen']\n",
      "Word:  royal\n",
      "['royal ------- is']\n",
      "['royal ------- the']\n",
      "['royal ------- queen']\n",
      "Word:  queen\n",
      "['queen ------- the']\n",
      "['queen ------- royal']\n"
     ]
    }
   ],
   "source": [
    "# raw sentences is a list of sentences.\n",
    "corpus_raw = 'he is the king. the king is royal. she is the royal queen' \n",
    "raw_sentences = corpus_raw.split('.')\n",
    "sentences = []\n",
    "for sentence in raw_sentences:\n",
    "    sentences.append(sentence.split())\n",
    "\n",
    "print('------------Sentences----------')\n",
    "print(sentences)\n",
    "\n",
    "data = []\n",
    "WINDOW_SIZE = 2\n",
    "for sentence in sentences:\n",
    "    print('\\n')\n",
    "    print('-----------Word Pairs-------')\n",
    "    for word_index, word in enumerate(sentence):\n",
    "        print (\"Word:  \"+ word)\n",
    "        for nb_word in sentence[max(word_index - WINDOW_SIZE, 0) : min(word_index + WINDOW_SIZE, len(sentence)) + 1] : \n",
    "            if nb_word != word:\n",
    "                print ([word + ' ------- '+ nb_word])\n",
    "                data.append([word, nb_word])\n",
    "#print('\\n')\n",
    "#print('------------Word Pairs in form of list----------')\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convert categorical data into binary format. \n",
    "\n",
    "\n",
    "* If word is present, then value at that word index is 1 and if not then value at that word index is zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'is', 'the', 'king', 'the', 'king', 'is', 'royal', 'she', 'is', 'the', 'royal', 'queen']\n",
      "{'is', 'the', 'she', 'royal', 'king', 'queen', 'he'}\n"
     ]
    }
   ],
   "source": [
    "corpus_raw = 'he is the king the king is royal she is the royal queen' \n",
    "words = []\n",
    "for word in corpus_raw.split(' '):\n",
    "    if word != '.': # because we don't want to treat . as a word\n",
    "        words.append(word)\n",
    "print (words)\n",
    "words = set(words) # so that all duplicate words are removed\n",
    "print (words)\n",
    "word2int = {}\n",
    "int2word = {}\n",
    "vocab_size = len(words) # gives the total number of unique words\n",
    "for i,word in enumerate(words):\n",
    "    word2int[word] = i\n",
    "    int2word[i] = word\n",
    "\n",
    "# function to convert numbers to one hot vectors\n",
    "def to_one_hot(data_point_index, vocab_size):\n",
    "    temp = np.zeros(vocab_size)\n",
    "    temp[data_point_index] = 1\n",
    "    return temp\n",
    "x_train = [] # input word\n",
    "y_train = [] # output word\n",
    "for data_word in data:\n",
    "    x_train.append(to_one_hot(word2int[ data_word[0] ], vocab_size))\n",
    "    y_train.append(to_one_hot(word2int[ data_word[1] ], vocab_size))\n",
    "\n",
    "# convert them to numpy arrays\n",
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Bag of Words (CBOW)\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This model tries to predict a word based on its neighbours\n",
    "\n",
    "\n",
    "* CBOW is learning to predict the word by the context. A context may be single word or multiple word for a given target words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example:__ The cat jumped over the puddle.\n",
    "\n",
    "__Input words or Context words:__ {“The”, “cat”, ’over”, “the’, “puddle”}\n",
    "\n",
    "__Output word or target word:__ We try to predict or generate center word \"jumped\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jalajthanaki/Pune_meetup/master/Day_3/Word2Vec/images/Image_1_6.png\" \n",
    "align=\"middle\" alt=\"Image_1_6\" data-canonical-src=\"\" style=\"width:80%;height:80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jalajthanaki/Pune_meetup/master/Day_3/Word2Vec/images/Image_1_7.png\" \n",
    "align=\"middle\" alt=\"Image_1_7\" data-canonical-src=\"\" style=\"width:80%;height:80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;\">Image credit goes to [Xin Rong](https://docs.google.com/presentation/d/1yQWN1CDWLzxGeIAvnGgDsIJr5xmy4dB0VmHFKkLiibo/pub?start=false&loop=false&delayms=3000&slide=id.p)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip-Gram\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This model tries to predict the neighbours of a given word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example:__ The cat jumped over the puddle.\n",
    "\n",
    "__Input:__ The center word “jumped”\n",
    "\n",
    "__Output:__ The model will be able to predict or generate the surrounding words “The”, “cat”, “over”, “the”, “puddle”. \n",
    "\n",
    "Here we call the __word “jumped” the context__ and __surrounding words as target words__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jalajthanaki/Pune_meetup/master/Day_3/Word2Vec/images/Image_1_8.png\" \n",
    "align=\"middle\" alt=\"Image_1_8\" data-canonical-src=\"\" style=\"width:80%;height:80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jalajthanaki/Pune_meetup/master/Day_3/Word2Vec/images/Image_1_9.png\" \n",
    "align=\"middle\" alt=\"Image_1_9\" data-canonical-src=\"\" style=\"width:80%;height:80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;\">Image credit goes to [Xin Rong](https://docs.google.com/presentation/d/1yQWN1CDWLzxGeIAvnGgDsIJr5xmy4dB0VmHFKkLiibo/pub?start=false&loop=false&delayms=3000&slide=id.p)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math behind Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure Highlights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jalajthanaki/Pune_meetup/master/Day_3/Word2Vec/images/Image_1_10.png\" \n",
    "align=\"middle\" alt=\"Image_1_10\" data-canonical-src=\"\" style=\"width:80%;height:80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "Input Layer:\n",
    "    One Hot encoded Vector\n",
    "\n",
    "Hidden Layer:\n",
    "    Linear Calculation\n",
    "    \n",
    "Outpur Layer:\n",
    "    Softmax\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small math example\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Corpus:\n",
    "\n",
    "the dog saw a cat\n",
    "\n",
    "the dog chased a cat\n",
    "\n",
    "the cat climbed a tree\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 1 : There are total 8 unique words__\n",
    "\n",
    "`{ the, dog, saw, a, cat, chased, climbed, tree }`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 2 : Arrange them an alphabetical order__\n",
    "\n",
    "<table style='text-size:14px;text-align:center'>\n",
    "  <tr>\n",
    "    <th>Words</th>\n",
    "    <th>Index</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>a</td>\n",
    "    <td>1</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>cat</td>\n",
    "    <td>2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>chased</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>climed</td>\n",
    "    <td>4</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>dog</td>\n",
    "    <td class=\"tg-yw4l\">5</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>saw</td>\n",
    "    <td>6</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>the</td>\n",
    "    <td>7</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>tree</td>\n",
    "    <td>8</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 3 : Let's define dimension of input and output matrix__\n",
    "\n",
    "* Size of vocab is = V = 8\n",
    "\n",
    "* Input matrix = $[ V \\times N ] = [ 8 \\times 3 ]$\n",
    "\n",
    "* Output matrix = $[ N \\times V ] = [ 3 \\times 8 ]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 4 : Initialize random weight for input and output layer__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__$W_{I}$ = Input layer weight__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jalajthanaki/Pune_meetup/master/Day_3/Word2Vec/images/Image_1_11.png\" \n",
    "align=\"middle\" alt=\"Image_1_11\" data-canonical-src=\"\" style=\"width:40%;height:40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__$W_{O}$ = Output layer weight__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jalajthanaki/Pune_meetup/master/Day_3/Word2Vec/images/Image_1_12.png\" \n",
    "align=\"middle\" alt=\"Image_1_12\" data-canonical-src=\"\" style=\"width:80%;height:80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 5 : Suppose we want to learn relationship between word 'cat' and 'climbed'__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Input layer get this input which represent the one-hot encoding for word 'cat' =$ X_{cat}$ =  $[\\;0\\;1\\; 0\\; 0\\; 0\\; 0\\; 0\\; 0\\;]$\n",
    "\n",
    "* Weight of input layer is: \n",
    "\n",
    "* Perform $X_{cat} \\times W_{I} = [\\;0\\;1\\; 0\\; 0\\; 0\\; 0\\; 0\\; 0\\;] \\; \\times \\;$ $\\left[\\begin{array}\n",
    "{rrr}\n",
    "-0.094491 & -0.443977 & 0.313917 \\\\\n",
    "-0.490796 & -0.229903 & 0.06546  \\\\\n",
    " 0.072921 & 0.172246 & -0.357751 \\\\\n",
    " 0.104514 & -0.463000 & 0.079367 \\\\\n",
    "-0.226080 & -0.154659 & -0.038422 \\\\\n",
    " 0.406115 & -0.192794 & -0.441992 \\\\\n",
    " 0.181755 & 0.088268 & 0.277574 \\\\\n",
    "-0.055334 & 0.491792 & 0.263102 \n",
    "\\end{array}\\right]$\n",
    "\n",
    "\n",
    "\n",
    "* __So final output of hidden layer__\n",
    "\n",
    " $H_{output} = W_{I_{2^{nd\\; row}}}$ = $[-0.490796 \\; -0.229903 \\;0.06546 ]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Step 6 : Now let's perform matrix multiplication of $WI_{2^{nd\\;element}} \\times WO_{[3 \\times 8]}$ OR $H_{output} \\times WO_{[3 \\times 8]}$ __"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Perform $H_{Output} \\times W_{O} = $__\n",
    "\n",
    "$\\left[\\begin{smallmatrix}-0.490796& -0.229903 & 0.06546 \\end{smallmatrix}\\right] \\; \\times \\;$ $ \\left[\\begin{smallmatrix}\n",
    " 0.023074 & 0.479901\t&0.432148\t&0.37548\t&0.364732\t&-0.11984&\t0.26607\t&-0.351 \\\\\n",
    "-0.368008 &\t0.424778\t&-0.257104\t&-0.148817\t&0.033922\t&0.353574\t&-0.144942\t&0.130904 \\\\\n",
    " 0.422434\t&0.364503\t&0.467865\t&-0.020302\t&-0.438777\t&-0.438777\t&0.268529\t&-0.446787 \n",
    "\\end{smallmatrix}\\right]$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jalajthanaki/Pune_meetup/master/Day_3/Word2Vec/images/Image_1_13.png\" \n",
    "align=\"middle\" alt=\"Image_1_13\" data-canonical-src=\"\" style=\"width:80%;height:80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Output layer generate this result__\n",
    "\n",
    "$H_{} \\times W_{O}$ = $\\left[\\begin{matrix} 0.100934\t&-0.309330\t&-0.122361&\t-0.151399\t&-0.215530\t&-0.051193\t&-0.0796855\t&0.1129275 \\end{matrix}\\right]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__We need Probability of the target word with respect to given context word __ \n",
    "\n",
    "* Context word is 'cat'\n",
    "\n",
    "* Target word is 'climbed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax function\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ y_{j} = Probability\\;(word_{j}\\; | \\;Word_{context}) = \\frac {exp(u_{j})}{\\sum_{j^{'}=1}^V exp(u_{j})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Softmax Probability \n",
      "\n",
      "[0.14981814 0.0994006  0.11983637 0.11640659 0.10917566 0.12867569\n",
      " 0.12506113 0.15162581]\n",
      "\n",
      "Error with repect to 'climbed' word\n",
      " \n",
      "[-0.14981814 -0.0994006   0.88016363 -0.11640659 -0.10917566 -0.12867569\n",
      " -0.12506113 -0.15162581]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def stablesoftmax(x):\n",
    "    shiftx = x - np.max(x)\n",
    "    #print (np.max(x))\n",
    "    #print (shiftx)\n",
    "    exps = np.exp(shiftx)\n",
    "    #print (exps)\n",
    "    #print (np.sum(exps))\n",
    "    print ('\\n Softmax Probability \\n')\n",
    "    print(exps / np.sum(exps))\n",
    "    print (\"\\nError with repect to 'climbed' word\\n \")\n",
    "    return ([0,0,1,0,0,0,0,0] - (exps / np.sum(exps)))\n",
    "\n",
    "print (stablesoftmax([0.100934,-0.309330,-0.122361,-0.151399,-0.215530,-0.051193,-0.0796855,0.1129275]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding of T-SNE \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start hands on session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Reading Sources:__\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__Research Papers:__\n",
    "\n",
    "* [Original Word2Vec Paper by Google](https://arxiv.org/pdf/1301.3781.pdf)\n",
    "\n",
    "* [word2vec Parameter Learning Explained](https://arxiv.org/pdf/1411.2738.pdf)\n",
    "\n",
    "* [How exactly does word2vec work?](http://www.1-4-5.net/~dmm/ml/how_does_word2vec_work.pdf)\n",
    "\n",
    "* [word2vec gradients](https://courses.cs.ut.ee/MTAT.03.277/2015_fall/uploads/Main/word2vec.pdf)\n",
    "\n",
    "* [Backpropagation in Woed2Vec](http://www.claudiobellei.com/2018/01/06/backprop-word2vec/)\n",
    "\n",
    "* [Cross Entropy Error](https://visualstudiomagazine.com/articles/2014/04/01/neural-network-cross-entropy-error.aspx)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__Commonly asked math based question for Word2Vec__\n",
    "\n",
    "* [Gradient Decent Steps](https://datascience.stackexchange.com/questions/5615/gradient-descent-step-for-word2vec-negative-sampling)\n",
    "\n",
    "* [Word2Vec Tutorial](http://mccormickml.com/assets/word2vec/Alex_Minnaar_Word2Vec_Tutorial_Part_I_The_Skip-Gram_Model.pdf)\n",
    "\n",
    "* [Gradient Decent Steps](https://stats.stackexchange.com/questions/134149/is-the-gradient-computation-in-the-word2vec-implementation-actually-wrong)\n",
    "\n",
    "\n",
    "\n",
    "__Fun Web interfaces for Word2Vec__\n",
    "\n",
    "\n",
    "* [twitter Word2vec](https://embeddings.macheads101.com/)\n",
    "* [Wevi by Xin Rong](https://ronxin.github.io/wevi/)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Resources(RNN)\n",
    "\n",
    "\n",
    "\n",
    "https://www.youtube.com/channel/UCeqlHZDmUEQQHYqnei8doYg/playlists\n",
    "\n",
    "\n",
    "0.10093404596\t-0.30933086135\t-0.12236108599599999\t-0.151399576249\t-0.215530118658\t-0.051193073102\t-0.07968558275399999\t0.112927496668\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "A1\tA2\tA3\n",
    "1\t-0.490796\t-0.229903\t0.06546\n",
    "Matrix B\n",
    "\n",
    "B1\tB2\tB3\tB4\tB5\tB6\tB7\tB8\n",
    "1\t0.023074\t0.479901\t0.432148\t0.37548\t0.364732\t-0.11984\t0.26607\t-0.351\n",
    "2\t-0.368008\t0.424778\t-0.257104\t-0.148817\t0.033922\t0.353574\t-0.144942\t0.130904\n",
    "3\t0.422434\t0.364503\t0.467865\t-0.020302\t-0.438777\t-0.438777\t0.268529\t-0.446787"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
