{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "div.cell { /* Tunes the space between cells */\n",
       "margin-top:1em;\n",
       "margin-bottom:1em;\n",
       "}\n",
       "\n",
       "div.text_cell_render h1 { /* Main titles bigger, centered */\n",
       "font-size: 2.0em;\n",
       "line-height:1.6em;\n",
       "text-align:center;\n",
       "}\n",
       "\n",
       "div.text_cell_render h2 { /*  Parts names nearer from text */\n",
       "margin-bottom: 1em;\n",
       "text-align:center;\n",
       "}\n",
       "\n",
       "\n",
       "div.text_cell_render { /* Customize text cells */\n",
       "font-family: 'Times New Roman';\n",
       "font-size:1.2em;\n",
       "line-height:1.2em;\n",
       "padding-left:1em;\n",
       "padding-right:3em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    "\n",
    "div.cell { /* Tunes the space between cells */\n",
    "margin-top:1em;\n",
    "margin-bottom:1em;\n",
    "}\n",
    "\n",
    "div.text_cell_render h1 { /* Main titles bigger, centered */\n",
    "font-size: 2.0em;\n",
    "line-height:1.6em;\n",
    "text-align:center;\n",
    "}\n",
    "\n",
    "div.text_cell_render h2 { /*  Parts names nearer from text */\n",
    "margin-bottom: 1em;\n",
    "text-align:center;\n",
    "}\n",
    "\n",
    "\n",
    "div.text_cell_render { /* Customize text cells */\n",
    "font-family: 'Times New Roman';\n",
    "font-size:1.2em;\n",
    "line-height:1.2em;\n",
    "padding-left:1em;\n",
    "padding-right:3em;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It's all about Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"\" \n",
    "align=\"middle\" alt=\"Image_1_1\" data-canonical-src=\"\" style=\"width:90%;height:90%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "1. Why do we need Word2Vec?\n",
    "\n",
    "2. What is Word2Vec?\n",
    "\n",
    "3. Architecture of Word2Vec\n",
    "\n",
    "4. Main Logic behind Word2Vec\n",
    "    \n",
    "    4.1 Vocabulary Builder\n",
    "    \n",
    "    4.2 Context Builder\n",
    "    \n",
    "    4.3 Skip-Gram\n",
    "    \n",
    "    4.4 Continuous Bag of Words\n",
    "    \n",
    "    4.5 Softmax function\n",
    "    \n",
    "    4.6 Small math example\n",
    "\n",
    "    4.7 Error Function\n",
    "\n",
    "5. Understanding of T-SNE \n",
    "    \n",
    "6. Let's start hands on session\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we need Word2Vec?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Semantics is important...!\n",
    "\n",
    "\n",
    "* Lexical Semantics and Distributional Semantics\n",
    "\n",
    "\n",
    "* We are focusing of Distributional Semantics\n",
    "\n",
    "\n",
    "* Computer cannot do computations on strings\n",
    "\n",
    "\n",
    "* Strings donâ€™t hold much explicit information themselves.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Facts:__\n",
    "\n",
    "\n",
    "* Is Word2Vec having Deep Neural Networks? The answer is: __NO__ \n",
    "\n",
    "\n",
    "* It's has only 3 layers...!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Word2Vec?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Word2Vec is the representation of words in numerical format. \n",
    "\n",
    "\n",
    "* Words Vectors are usually dense vector representations\n",
    "\n",
    "\n",
    "* It generates high-dimensional vector space for words. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture of Word2Vec\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Logic behind Word2Vec\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary Builder\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Builder\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip-Gram\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Bag of Words\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax function\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small math example\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding of T-SNE \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start hands on session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://embeddings.macheads101.com/\n",
    "https://ronxin.github.io/wevi/\n",
    "    \n",
    "    \n",
    "Reading Resources(RNN)\n",
    "\n",
    "\n",
    "\n",
    "https://www.youtube.com/channel/UCeqlHZDmUEQQHYqnei8doYg/playlists\n",
    "\n",
    "\n",
    "0.10093404596\t-0.30933086135\t-0.12236108599599999\t-0.151399576249\t-0.215530118658\t-0.051193073102\t-0.07968558275399999\t0.112927496668\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "A1\tA2\tA3\n",
    "1\t-0.490796\t-0.229903\t0.06546\n",
    "Matrix B\n",
    "\n",
    "B1\tB2\tB3\tB4\tB5\tB6\tB7\tB8\n",
    "1\t0.023074\t0.479901\t0.432148\t0.37548\t0.364732\t-0.11984\t0.26607\t-0.351\n",
    "2\t-0.368008\t0.424778\t-0.257104\t-0.148817\t0.033922\t0.353574\t-0.144942\t0.130904\n",
    "3\t0.422434\t0.364503\t0.467865\t-0.020302\t-0.438777\t-0.438777\t0.268529\t-0.446787"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Reading Sources:__\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__Research Papers:__\n",
    "\n",
    "* [Original Word2Vec Paper by Google](https://arxiv.org/pdf/1301.3781.pdf)\n",
    "\n",
    "* [word2vec Parameter Learning Explained](https://arxiv.org/pdf/1411.2738.pdf)\n",
    "\n",
    "* [How exactly does word2vec work?](http://www.1-4-5.net/~dmm/ml/how_does_word2vec_work.pdf)\n",
    "\n",
    "* [word2vec gradients](https://courses.cs.ut.ee/MTAT.03.277/2015_fall/uploads/Main/word2vec.pdf)\n",
    "\n",
    "* [Backpropagation in Woed2Vec](http://www.claudiobellei.com/2018/01/06/backprop-word2vec/)\n",
    "\n",
    "* [Cross Entropy Error](https://visualstudiomagazine.com/articles/2014/04/01/neural-network-cross-entropy-error.aspx)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__Commonly asked math based question for Word2Vec__\n",
    "\n",
    "* [Gradient Decent Steps](https://datascience.stackexchange.com/questions/5615/gradient-descent-step-for-word2vec-negative-sampling)\n",
    "\n",
    "* [Word2Vec Tutorial](http://mccormickml.com/assets/word2vec/Alex_Minnaar_Word2Vec_Tutorial_Part_I_The_Skip-Gram_Model.pdf)\n",
    "\n",
    "* [Gradient Decent Steps](https://stats.stackexchange.com/questions/134149/is-the-gradient-computation-in-the-word2vec-implementation-actually-wrong)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
